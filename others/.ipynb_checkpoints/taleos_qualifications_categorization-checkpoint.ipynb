{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\D\\Installation\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, ExcelFile, read_csv, read_excel \n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, make_scorer\n",
    "from sklearn.externals import joblib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../2016 - 2018 Taleo Job Postings - Updated.xlsx'\n",
    "xls = ExcelFile(path, sep = ';', encoding = 'utf-8')\n",
    "df = read_excel(xls, 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifications_external = DataFrame(df[['Qualifications - External']])\n",
    "qualifications_external.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: find a better split than ' - ' because of cases like '2 - 4 years in a directly related position.(Asset)', \n",
    "#yet similar cases like '4 â€“ 6 years commercial experience (asset).' has a bigger hyphen. \n",
    "#The similar cases appear way more than the first one.\n",
    "\n",
    "all_values = [value.replace('\\xa0', '').lower().strip() for row in qualifications_external.values for value in ''.join(row).split(' - ')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def transform_data_to_tfidf(texts, tfidf_model):\n",
    "        strs = []\n",
    "        for text in texts:\n",
    "            stra = tokenize_text(text)\n",
    "            stra = ' '.join(stra)\n",
    "            strs.append(stra)\n",
    "        response = tfidf_model.transform(strs)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_bow(tokenized_texts):\n",
    "        bow = []\n",
    "        for tokenized_text in tokenized_texts:\n",
    "            bow.extend(tokenized_text)\n",
    "        return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def tokenize_text(text):\n",
    "        return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_tf_idf_model(train_X, stopwords):\n",
    "        tokenized_texts = [tokenize_text(text) for text in train_X]\n",
    "        bow = get_bow(tokenized_texts)\n",
    "        tfidf = TfidfVectorizer(tokenizer=tokenize_text, stop_words=stopwords)\n",
    "        tfs = tfidf.fit_transform(bow)\n",
    "        return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generating_stratified_k_folds(X, y, n_folds, stopwords_):\n",
    "        skf = StratifiedKFold(n_splits=n_folds, random_state=0)\n",
    "        k_folds = []\n",
    "        for train, test in skf.split(X, y):\n",
    "            train_x = [X[i] for i in train]\n",
    "            test_x = [X[i] for i in test]\n",
    "\n",
    "            tfidf = get_tf_idf_model(train_x, stopwords_)\n",
    "            #joblib.dump(tfidf, 'tfidf'+self.time_of_training_+'.pkl')\n",
    "\n",
    "            train_x = transform_data_to_tfidf(train_x, tfidf)\n",
    "            test_x = transform_data_to_tfidf(test_x, tfidf)\n",
    "\n",
    "            train_y = [y[i] for i in train]\n",
    "            test_y = [y[i] for i in test]\n",
    "\n",
    "            k_folds.append([train_x, train_y, test_x, test_y])\n",
    "            break\n",
    "        return tfidf, k_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = read_csv('total_jp.csv', sep=';', encoding='utf-8', usecols=['CA', 'CP', 'EI', 'ER', 'TS'])\n",
    "\n",
    "examples = dict()\n",
    "\n",
    "for column in total.columns:\n",
    "    selected_column = DataFrame(total[[column]])\n",
    "    selected_column.dropna(inplace=True)\n",
    "    column_values = [value.lower().strip() for row in selected_column.values for value in ''.join(row).split('$$$%%%&&&')]\n",
    "    examples[column] = column_values\n",
    "    \n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for key, values in examples.items():\n",
    "    for value in values:\n",
    "        X.append(value)\n",
    "        y.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words('english')\n",
    "tfidfmodel, kfolds = generating_stratified_k_folds(X, y, 5, en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_parameters = {'n_estimators':[50, 200], 'criterion':['gini', 'entropy'],\n",
    "#                    'class_weight': ['balanced', 'balanced_subsample' or None]}\n",
    "#clf = GridSearchCV(RandomForestClassifier(random_state = 12), tuned_parameters, cv=5, return_train_score=True)\n",
    "#model = clf.fit(kfolds[0][0], kfolds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'n_estimators':[50]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state = 12), tuned_parameters, cv=5, return_train_score=True)\n",
    "model = clf.fit(kfolds[0][0], kfolds[0][1])\n",
    "print(model.classes_)\n",
    "confusion_matrix(model.predict(kfolds[0][2]), kfolds[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(model.predict(kfolds[0][0]), kfolds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_training_ = (str(datetime.datetime.now().date()) + \" \" + str(datetime.datetime.now().time())).replace(':', '')\n",
    "joblib.dump(model, 'classifier'+time_of_training_+'.pkl')\n",
    "joblib.dump(tfidfmodel, 'tfidf_model'+time_of_training_+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 260,   10,    2,    0,    0,    1],\n",
       "       [  31,  381,    0,    1,    2,   10],\n",
       "       [   0,    0,  231,   27,    8,    1],\n",
       "       [   0,    0,   51,  493,   30,    2],\n",
       "       [   1,   10,   14,   63, 1028,   27],\n",
       "       [   8,   17,    4,   11,   17, 1992]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rfc = RandomForestClassifier(n_estimators=50, random_state=12)\n",
    "#rfc.fit(kfolds[0][0], kfolds[0][1])\n",
    "#conf_matrix = confusion_matrix(rfc.predict(kfolds[0][2]), kfolds[0][3])\n",
    "#conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bs in chemical engineering, environmental engineering or other technical degree', 'CA'), ('minimum of 2 years of experience as an environmental engineer/specialist', 'ER'), ('proficient in use of excel, word and air services', 'TS'), ('ability to negotiate with regulatory agencies assets:', 'TS'), (\"master's degree in engineering or mba\", 'CA'), ('professional engineers license', 'CP'), ('minimum of 2 years environmental experience in the petrochemical industry', 'EI'), ('or other relevant experience the lima refining company is an equal opportunity employer. all qualified applicants will receive consideration for employment without regard to race, color, religion, sex national origin, veteran status, disability, sexual orientation or gender identity.', 'ER'), (\"bachelor's degree in engineering\", 'CA'), ('professional engineer (p.eng)', 'CP'), ('specialization in engineering, process or mechanical engineering preferred', 'CA'), ('strong knowledge of capital afes and project delivery models', 'TS'), ('relevant experience in capital project management is required', 'ER'), ('understanding of downstream operations within oil and gas industry would be an asset', 'EI'), ('strong computer skills and expertise with ms office tools', 'TS'), ('excellent oral and written communication skills', 'TS'), ('strong analytical and problem solving skills', 'TS'), ('strong financial acumen', 'TS'), ('working knowledge of sap and/or other reporting systems would be an asset', 'TS'), ('travel for this position would be up to 25% of the time  husky energy is an equal opportunity employer. we are committed to a diverse workforce and a respectful work environment. we value diversity of expertise, talent and opinion which is leveraged for an innovative and productive work environment. we are focused on attracting and retaining the best talent by encouraging applications from all qualified individuals including visible minorities, aboriginal people, women and people with disabilities.', 'TS')]\n"
     ]
    }
   ],
   "source": [
    "taleo_tests = all_values[0:20]\n",
    "taleo_tfidf = transform_data_to_tfidf(taleo_tests, tfidfmodel)\n",
    "print([(item, predicted_class) for item, predicted_class in zip(taleo_tests, model.predict(taleo_tfidf))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'CP', 'EI', 'ER', 'TS', 'responsabilities'], dtype='<U16')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
